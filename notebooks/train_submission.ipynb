{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00ba9e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:35:34.552471Z",
     "iopub.status.busy": "2025-05-05T19:35:34.552111Z",
     "iopub.status.idle": "2025-05-05T19:35:40.730598Z",
     "shell.execute_reply": "2025-05-05T19:35:40.729868Z"
    },
    "papermill": {
     "duration": 6.183672,
     "end_time": "2025-05-05T19:35:40.732057",
     "exception": false,
     "start_time": "2025-05-05T19:35:34.548385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\r\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\r\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\r\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\r\n",
      "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\r\n",
      "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b3040",
   "metadata": {
    "papermill": {
     "duration": 0.002039,
     "end_time": "2025-05-05T19:35:40.736941",
     "exception": false,
     "start_time": "2025-05-05T19:35:40.734902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Полная версия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06b87de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:35:40.742589Z",
     "iopub.status.busy": "2025-05-05T19:35:40.742337Z",
     "iopub.status.idle": "2025-05-05T19:35:52.733173Z",
     "shell.execute_reply": "2025-05-05T19:35:52.732561Z"
    },
    "papermill": {
     "duration": 11.995501,
     "end_time": "2025-05-05T19:35:52.734564",
     "exception": false,
     "start_time": "2025-05-05T19:35:40.739063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 2.82M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from jiwer import cer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "DATA_DIR = '/kaggle/input/asr-numbers-recognition-in-russian' \n",
    "df_train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "df_train['transcription'] = df_train['transcription'].astype(str)\n",
    "df_dev   = pd.read_csv(os.path.join(DATA_DIR, 'dev.csv'))\n",
    "df_dev ['transcription'] = df_dev ['transcription'].astype(str)\n",
    "\n",
    "def text_to_indices(text, char2idx):\n",
    "    return [char2idx[c] for c in text]\n",
    "\n",
    "def build_vocab(transcripts):\n",
    "    texts = transcripts.astype(str)\n",
    "    chars = sorted(set(''.join(texts)))\n",
    "    char2idx = {c: i+1 for i, c in enumerate(chars)}  # 0 — CTC blank\n",
    "    idx2char = {i: c for c, i in char2idx.items()}\n",
    "    return char2idx, idx2char\n",
    "\n",
    "char2idx, idx2char = build_vocab(df_train['transcription'])\n",
    "vocab_size = len(char2idx) + 1  # include CTC blank\n",
    "\n",
    "resampler = torchaudio.transforms.Resample(orig_freq=24000, new_freq=16000)\n",
    "mel_spec  = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128)\n",
    "\n",
    "class ASRDataset(Dataset):\n",
    "    def __init__(self, df, data_base, char2idx):\n",
    "        self.df = df\n",
    "        self.base = data_base\n",
    "        self.char2idx = char2idx\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        wav, sr = torchaudio.load(os.path.join(self.base, row['filename']))\n",
    "        if sr != 16000:\n",
    "            wav = resampler(wav)\n",
    "        spec = mel_spec(wav).squeeze(0).transpose(0,1)  # T x n_mels\n",
    "        target = torch.tensor(text_to_indices(row['transcription'], self.char2idx), dtype=torch.long)\n",
    "        return spec, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    specs, targets = zip(*batch)\n",
    "    spec_lens = [s.size(0) for s in specs]\n",
    "    max_spec  = max(spec_lens)\n",
    "    padded_specs = torch.zeros(len(specs), max_spec, specs[0].size(1))\n",
    "    for i, s in enumerate(specs):\n",
    "        padded_specs[i, :s.size(0)] = s\n",
    "    tgt_lens = [t.size(0) for t in targets]\n",
    "    targets_cat = torch.cat(targets)\n",
    "    return padded_specs.transpose(1,2), torch.tensor(spec_lens), targets_cat, torch.tensor(tgt_lens)\n",
    "\n",
    "train_ds = ASRDataset(df_train, DATA_DIR, char2idx)\n",
    "dev_ds   = ASRDataset(df_dev,   DATA_DIR, char2idx)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "dev_loader   = DataLoader(dev_ds,   batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "class ASRModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d((2,1)),\n",
    "            nn.Conv2d(32,64,3, padding=1), nn.ReLU(), nn.MaxPool2d((2,1)),\n",
    "            nn.Conv2d(64,64,3, padding=1), nn.ReLU(), nn.MaxPool2d((2,1)),\n",
    "        )\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=64*16,\n",
    "            hidden_size=192,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.classifier = nn.Linear(192*2, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (B,1,n_mels,T)\n",
    "        x = self.cnn(x)     # (B,64,16,T′)\n",
    "        B, C, H, W = x.size()\n",
    "        x = x.permute(0,3,1,2).reshape(B, W, C*H)  # (B,T′,1024)\n",
    "        x, _ = self.rnn(x)                       # (B,T′,384)\n",
    "        x = self.classifier(x)                   # (B,T′,vocab)\n",
    "        return x.log_softmax(2)\n",
    "\n",
    "model = ASRModel(vocab_size)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {num_params/1e6:.2f}M\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "ctc_loss  = nn.CTCLoss(blank=0, zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f49bec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:35:52.740787Z",
     "iopub.status.busy": "2025-05-05T19:35:52.740446Z",
     "iopub.status.idle": "2025-05-05T23:00:23.250234Z",
     "shell.execute_reply": "2025-05-05T23:00:23.249411Z"
    },
    "papermill": {
     "duration": 12270.514393,
     "end_time": "2025-05-05T23:00:23.251527",
     "exception": false,
     "start_time": "2025-05-05T19:35:52.737134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E1/40: 100%|██████████| 785/785 [07:12<00:00,  1.82batch/s, loss=2.4713, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 1: train loss 2.8925, dev CER 1.0000\n",
      "   *** New best Dev CER 1.0000 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E2/40: 100%|██████████| 785/785 [04:34<00:00,  2.86batch/s, loss=1.2983, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 2: train loss 2.0244, dev CER 0.7803\n",
      "   *** New best Dev CER 0.7803 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E3/40: 100%|██████████| 785/785 [04:27<00:00,  2.94batch/s, loss=0.3520, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 3: train loss 0.8445, dev CER 0.3463\n",
      "   *** New best Dev CER 0.3463 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E4/40: 100%|██████████| 785/785 [04:26<00:00,  2.94batch/s, loss=0.2249, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 4: train loss 0.4640, dev CER 0.2859\n",
      "   *** New best Dev CER 0.2859 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E5/40: 100%|██████████| 785/785 [04:27<00:00,  2.93batch/s, loss=0.1247, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 5: train loss 0.3449, dev CER 0.2686\n",
      "   *** New best Dev CER 0.2686 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E6/40: 100%|██████████| 785/785 [04:36<00:00,  2.84batch/s, loss=0.0630, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 6: train loss 0.2737, dev CER 0.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E7/40: 100%|██████████| 785/785 [04:27<00:00,  2.93batch/s, loss=0.2348, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 7: train loss 0.2082, dev CER 0.2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E8/40: 100%|██████████| 785/785 [04:29<00:00,  2.91batch/s, loss=0.1587, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 8: train loss 0.1617, dev CER 0.2088\n",
      "   *** New best Dev CER 0.2088 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E9/40: 100%|██████████| 785/785 [04:28<00:00,  2.93batch/s, loss=0.0715, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 9: train loss 0.1353, dev CER 0.2287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E10/40: 100%|██████████| 785/785 [04:28<00:00,  2.92batch/s, loss=0.1110, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 10: train loss 0.1358, dev CER 0.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E11/40: 100%|██████████| 785/785 [04:29<00:00,  2.91batch/s, loss=0.0647, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 11: train loss 0.1116, dev CER 0.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E12/40: 100%|██████████| 785/785 [04:28<00:00,  2.92batch/s, loss=0.0790, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 12: train loss 0.1003, dev CER 0.2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E13/40: 100%|██████████| 785/785 [04:29<00:00,  2.91batch/s, loss=0.1682, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 13: train loss 0.1018, dev CER 0.2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E14/40: 100%|██████████| 785/785 [04:26<00:00,  2.95batch/s, loss=0.0660, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 14: train loss 0.0859, dev CER 0.1933\n",
      "   *** New best Dev CER 0.1933 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E15/40: 100%|██████████| 785/785 [04:32<00:00,  2.88batch/s, loss=0.0343, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 15: train loss 0.0873, dev CER 0.2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E16/40: 100%|██████████| 785/785 [04:28<00:00,  2.92batch/s, loss=0.0057, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 16: train loss 0.0789, dev CER 0.2117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E17/40: 100%|██████████| 785/785 [04:29<00:00,  2.92batch/s, loss=0.0583, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 17: train loss 0.0765, dev CER 0.2226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E18/40: 100%|██████████| 785/785 [04:31<00:00,  2.90batch/s, loss=0.0169, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 18: train loss 0.0685, dev CER 0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E19/40: 100%|██████████| 785/785 [04:32<00:00,  2.88batch/s, loss=0.1352, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 19: train loss 0.0683, dev CER 0.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E20/40: 100%|██████████| 785/785 [04:30<00:00,  2.90batch/s, loss=0.0598, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 20: train loss 0.0634, dev CER 0.2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E21/40: 100%|██████████| 785/785 [04:29<00:00,  2.91batch/s, loss=0.0036, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 21: train loss 0.0677, dev CER 0.1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E22/40: 100%|██████████| 785/785 [04:37<00:00,  2.83batch/s, loss=0.0182, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 22: train loss 0.0607, dev CER 0.1837\n",
      "   *** New best Dev CER 0.1837 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E23/40: 100%|██████████| 785/785 [04:37<00:00,  2.82batch/s, loss=0.0141, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 23: train loss 0.0558, dev CER 0.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E24/40: 100%|██████████| 785/785 [04:31<00:00,  2.89batch/s, loss=0.0065, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 24: train loss 0.0550, dev CER 0.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E25/40: 100%|██████████| 785/785 [04:33<00:00,  2.87batch/s, loss=0.0016, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 25: train loss 0.0577, dev CER 0.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E26/40: 100%|██████████| 785/785 [04:29<00:00,  2.91batch/s, loss=0.0032, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 26: train loss 0.0648, dev CER 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E27/40: 100%|██████████| 785/785 [04:30<00:00,  2.91batch/s, loss=0.0029, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 27: train loss 0.0478, dev CER 0.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E28/40: 100%|██████████| 785/785 [04:32<00:00,  2.88batch/s, loss=0.0123, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 28: train loss 0.0589, dev CER 0.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E29/40: 100%|██████████| 785/785 [04:30<00:00,  2.90batch/s, loss=0.0024, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 29: train loss 0.0483, dev CER 0.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E30/40: 100%|██████████| 785/785 [04:29<00:00,  2.91batch/s, loss=0.0655, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 30: train loss 0.0456, dev CER 0.1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E31/40: 100%|██████████| 785/785 [04:30<00:00,  2.90batch/s, loss=0.0369, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 31: train loss 0.0499, dev CER 0.1877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E32/40: 100%|██████████| 785/785 [04:30<00:00,  2.90batch/s, loss=0.0100, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 32: train loss 0.0486, dev CER 0.1777\n",
      "   *** New best Dev CER 0.1777 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E33/40: 100%|██████████| 785/785 [04:32<00:00,  2.88batch/s, loss=0.0076, lr=1.00e-03]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 33: train loss 0.0532, dev CER 0.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E34/40: 100%|██████████| 785/785 [04:32<00:00,  2.89batch/s, loss=0.0933, lr=5.00e-04]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 34: train loss 0.0375, dev CER 0.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E35/40: 100%|██████████| 785/785 [04:30<00:00,  2.90batch/s, loss=0.0011, lr=5.00e-04]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 35: train loss 0.0302, dev CER 0.1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E36/40: 100%|██████████| 785/785 [04:30<00:00,  2.90batch/s, loss=0.0171, lr=5.00e-04]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 36: train loss 0.0335, dev CER 0.1970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E37/40: 100%|██████████| 785/785 [04:33<00:00,  2.87batch/s, loss=0.0359, lr=5.00e-04]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 37: train loss 0.0313, dev CER 0.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E38/40: 100%|██████████| 785/785 [04:32<00:00,  2.89batch/s, loss=0.0470, lr=5.00e-04]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 38: train loss 0.0287, dev CER 0.1838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E39/40: 100%|██████████| 785/785 [04:32<00:00,  2.89batch/s, loss=0.0063, lr=5.00e-04]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 39: train loss 0.0254, dev CER 0.1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E40/40: 100%|██████████| 785/785 [04:31<00:00,  2.89batch/s, loss=0.0043, lr=5.00e-04]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Epoch 40: train loss 0.0274, dev CER 0.1909\n",
      "\n",
      "Loaded best model with Dev CER=0.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "import torchaudio\n",
    "# import torchaudio.sox_effects as sox_fx\n",
    "import torchaudio.functional as F\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "time_mask = TimeMasking(time_mask_param=50)\n",
    "freq_mask = FrequencyMasking(freq_mask_param=20)\n",
    "\n",
    "def speed_perturb(wav, sr):\n",
    "    # factor = random.choice([0.9, 1.0, 1.1])\n",
    "    # effects = [['speed', str(factor)], ['rate', str(sr)]]\n",
    "    # wav, _ = sox_fx.apply_effects_tensor(wav, sr, effects)\n",
    "    # return wav\n",
    "    factor = random.choice([0.9, 1.0, 1.1])\n",
    "    new_sr = int(sr * factor)\n",
    "    # down/up-sample to simulate speed change\n",
    "    wav = F.resample(wav, orig_freq=sr, new_freq=new_sr)\n",
    "    return F.resample(wav, orig_freq=new_sr, new_freq=sr)\n",
    "\n",
    "# Augmented Dataset\n",
    "class ASRAugDataset(ASRDataset):\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        wav, sr = torchaudio.load(os.path.join(self.base, row['filename']))\n",
    "        if sr != 16000:\n",
    "            wav = resampler(wav)\n",
    "        # speed perturb\n",
    "        if random.random() < 0.5:\n",
    "            wav = speed_perturb(wav, 16000)\n",
    "        # gaussian noise\n",
    "        if random.random() < 0.5:\n",
    "            wav = wav + 0.005 * torch.randn_like(wav)\n",
    "        # random gain\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(-6, +6)\n",
    "            wav = torchaudio.functional.gain(wav, gain)\n",
    "        # mel-spectrogram\n",
    "        spec = mel_spec(wav).squeeze(0).transpose(0,1)\n",
    "        # SpecAugment\n",
    "        spec = time_mask(freq_mask(spec))\n",
    "        target = torch.tensor(text_to_indices(row['transcription'], self.char2idx), dtype=torch.long)\n",
    "        return spec, target\n",
    "\n",
    "# recreate loader\n",
    "train_aug_ds = ASRAugDataset(df_train, DATA_DIR, char2idx)\n",
    "train_loader = DataLoader(train_aug_ds, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# scheduler and best-tracking\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "best_cer = float('inf')\n",
    "best_state = None\n",
    "\n",
    "def greedy_decode(log_probs):\n",
    "    inds = log_probs.argmax(-1).cpu().numpy()\n",
    "    seq, prev = [], 0\n",
    "    for idx in inds:\n",
    "        if idx and idx != prev:\n",
    "            seq.append(idx2char[idx])\n",
    "        prev = idx\n",
    "    return ''.join(seq)\n",
    "\n",
    "# run training+eval\n",
    "num_epochs = 40\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Train E{epoch}/{num_epochs}\", unit='batch')\n",
    "    for specs, spec_lens, targets, tgt_lens in pbar:\n",
    "        specs, targets = specs.to(device), targets.to(device)\n",
    "        spec_lens, tgt_lens = spec_lens.to(device), tgt_lens.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        lp = model(specs).permute(1,0,2)\n",
    "        loss = ctc_loss(lp, targets, spec_lens, tgt_lens)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_loss += batch_loss\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(loss=f\"{batch_loss:.4f}\", lr=f\"{lr:.2e}\")\n",
    "    avg_train = total_loss / len(train_loader)\n",
    "    scheduler.step(avg_train)\n",
    "\n",
    "    # eval\n",
    "    model.eval()\n",
    "    all_refs, all_hyps = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, spec_lens, targets, tgt_lens in tqdm(dev_loader, desc=\" Eval\", leave=False):\n",
    "            specs = specs.to(device)\n",
    "            lp = model(specs)\n",
    "            flat = targets.tolist()\n",
    "            lens = tgt_lens.tolist()\n",
    "            off = 0\n",
    "            for i, L in enumerate(lens):\n",
    "                hy = greedy_decode(lp[i])\n",
    "                ref_idxs = flat[off:off+L]; off += L\n",
    "                rf = ''.join(idx2char[x] for x in ref_idxs)\n",
    "                all_hyps.append(hy); all_refs.append(rf)\n",
    "    cer_score = cer(all_refs, all_hyps)\n",
    "\n",
    "    print(f\"-> Epoch {epoch}: train loss {avg_train:.4f}, dev CER {cer_score:.4f}\")\n",
    "    if cer_score < best_cer:\n",
    "        best_cer, best_state = cer_score, copy.deepcopy(model.state_dict())\n",
    "        print(f\"   *** New best Dev CER {best_cer:.4f} ***\")\n",
    "\n",
    "# load best model\n",
    "model.load_state_dict(best_state)\n",
    "print(f\"\\nLoaded best model with Dev CER={best_cer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d62a7dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:00:29.452998Z",
     "iopub.status.busy": "2025-05-05T23:00:29.452680Z",
     "iopub.status.idle": "2025-05-05T23:00:29.474695Z",
     "shell.execute_reply": "2025-05-05T23:00:29.474119Z"
    },
    "papermill": {
     "duration": 3.059767,
     "end_time": "2025-05-05T23:00:29.475891",
     "exception": false,
     "start_time": "2025-05-05T23:00:26.416124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea48dacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:00:35.571861Z",
     "iopub.status.busy": "2025-05-05T23:00:35.571563Z",
     "iopub.status.idle": "2025-05-05T23:00:35.605535Z",
     "shell.execute_reply": "2025-05-05T23:00:35.604748Z"
    },
    "papermill": {
     "duration": 3.004134,
     "end_time": "2025-05-05T23:00:35.606724",
     "exception": false,
     "start_time": "2025-05-05T23:00:32.602590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/756633090.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ASRModel(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rnn): LSTM(1024, 192, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (classifier): Linear(in_features=384, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(best_state, 'best_model.pth')\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80bb88f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:00:41.814139Z",
     "iopub.status.busy": "2025-05-05T23:00:41.813401Z",
     "iopub.status.idle": "2025-05-05T23:25:41.202022Z",
     "shell.execute_reply": "2025-05-05T23:25:41.201281Z"
    },
    "papermill": {
     "duration": 1505.491165,
     "end_time": "2025-05-05T23:25:44.297817",
     "exception": false,
     "start_time": "2025-05-05T23:00:38.806652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune E1/5: 100%|██████████| 785/785 [04:31<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1: train loss 0.0393, dev CER 0.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune E2/5: 100%|██████████| 785/785 [04:30<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2: train loss 0.0394, dev CER 0.1772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune E3/5: 100%|██████████| 785/785 [04:30<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3: train loss 0.0348, dev CER 0.1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune E4/5: 100%|██████████| 785/785 [04:27<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4: train loss 0.0351, dev CER 0.1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune E5/5: 100%|██████████| 785/785 [04:28<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5: train loss 0.0324, dev CER 0.1770\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)  # мелкий LR\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "num_more_epochs = 5\n",
    "for epoch in range(1, num_more_epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for specs, spec_lens, targets, tgt_lens in tqdm(train_loader, desc=f\"Fine-tune E{epoch}/{num_more_epochs}\"):\n",
    "        specs, targets = specs.to(device), targets.to(device)\n",
    "        spec_lens, tgt_lens = spec_lens.to(device), tgt_lens.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        lp = model(specs).permute(1,0,2)\n",
    "        loss = ctc_loss(lp, targets, spec_lens, tgt_lens)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg = total_loss / len(train_loader)\n",
    "    scheduler.step(avg)\n",
    "\n",
    "    model.eval()\n",
    "    all_refs, all_hyps = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, spec_lens, targets, tgt_lens in dev_loader:\n",
    "            specs = specs.to(device)\n",
    "            lp = model(specs)\n",
    "            off = 0\n",
    "            flat = targets.tolist()\n",
    "            for i,L in enumerate(tgt_lens.tolist()):\n",
    "                hy = greedy_decode(lp[i])\n",
    "                rf = ''.join(idx2char[x] for x in flat[off:off+L])\n",
    "                off += L\n",
    "                all_hyps.append(hy); all_refs.append(rf)\n",
    "    cer_score = cer(all_refs, all_hyps)\n",
    "    print(f\"Fine-tune Epoch {epoch}: train loss {avg:.4f}, dev CER {cer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b8939ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:25:50.579029Z",
     "iopub.status.busy": "2025-05-05T23:25:50.578371Z",
     "iopub.status.idle": "2025-05-05T23:27:37.909571Z",
     "shell.execute_reply": "2025-05-05T23:27:37.908939Z"
    },
    "papermill": {
     "duration": 110.540004,
     "end_time": "2025-05-05T23:27:37.910689",
     "exception": false,
     "start_time": "2025-05-05T23:25:47.370685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 2582/2582 [01:47<00:00, 24.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls in transcription: 0\n",
      "Saved → predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "BASE     = '/kaggle/input/asr-numbers-recognition-in-russian'\n",
    "TEST_CSV = os.path.join(BASE, 'test.csv')\n",
    "OUT_CSV  = 'predictions.csv'\n",
    "\n",
    "df = pd.read_csv(TEST_CSV) \n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "for fn in tqdm(df['filename'], desc='Inference'):\n",
    "    wav, sr = torchaudio.load(os.path.join(BASE, fn))\n",
    "    if sr != 16000:\n",
    "        wav = resampler(wav)\n",
    "    spec = mel_spec(wav).squeeze(0).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logp = model(spec)\n",
    "    preds.append(greedy_decode(logp[0]))\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    'filename': df['filename'],\n",
    "    'transcription': preds\n",
    "})\n",
    "\n",
    "out['transcription'] = out['transcription'].fillna(0)\n",
    "\n",
    "n_null = out['transcription'].isna().sum()\n",
    "print(f\"Nulls in transcription: {n_null}\")\n",
    "\n",
    "out['transcription'] = pd.to_numeric(out['transcription'], errors='coerce').fillna(0).astype(int)\n",
    "out['transcription'] = out['transcription'].apply(lambda x: int(x) if x >= 0 else 0)\n",
    "\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved → {OUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "541922f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:27:44.271247Z",
     "iopub.status.busy": "2025-05-05T23:27:44.270921Z",
     "iopub.status.idle": "2025-05-05T23:27:44.291664Z",
     "shell.execute_reply": "2025-05-05T23:27:44.290891Z"
    },
    "papermill": {
     "duration": 3.244079,
     "end_time": "2025-05-05T23:27:44.293360",
     "exception": false,
     "start_time": "2025-05-05T23:27:41.049281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_best_2.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11819802,
     "sourceId": 99036,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13940.629725,
   "end_time": "2025-05-05T23:27:50.495775",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-05T19:35:29.866050",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
